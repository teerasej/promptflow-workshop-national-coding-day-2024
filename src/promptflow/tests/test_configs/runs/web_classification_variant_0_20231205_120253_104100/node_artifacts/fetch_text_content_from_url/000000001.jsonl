{"node_name": "fetch_text_content_from_url", "line_number": 1, "run_info": {"node": "fetch_text_content_from_url", "flow_run_id": "web_classification_variant_0_20231205_120253_104100", "run_id": "web_classification_variant_0_20231205_120253_104100_fetch_text_content_from_url_1", "status": "Completed", "inputs": {"url": "https://arxiv.org/abs/2307.04767"}, "output": "\n\n\n [2307.04767] Semantic-SAM: Segment and Recognize Anything at Any Granularity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n > cs > arXiv:2307.04767\n  \n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nopen search\n\n\n\n\n\n\nGO\n\n\n\nopen navigation menu\n\n\nquick links\n\nLogin\nHelp Pages\nAbout\n\n\n\n\n\n\n\n\n\n\n\n\nComputer Science > Computer Vision and Pattern Recognition\n\n\narXiv:2307.04767 (cs)\n    \n\n\n\n\n  [Submitted on 10 Jul 2023]\nTitle:Semantic-SAM: Segment and Recognize Anything at Any Granularity\nAuthors:Feng Li, Hao Zhang, Peize Sun, Xueyan Zou, Shilong Liu, Jianwei Yang, Chunyuan Li, Lei Zhang, Jianfeng Gao Download a PDF of the paper titled Semantic-SAM: Segment and Recognize Anything at Any Granularity, by Feng Li and 8 other authors\nDownload PDF\n\nAbstract:In this paper, we introduce Semantic-SAM, a universal image segmentation model to enable segment and recognize anything at any desired granularity. Our model offers two key advantages: semantic-awareness and granularity-abundance. To achieve semantic-awareness, we consolidate multiple datasets across three granularities and introduce decoupled classification for objects and parts. This allows our model to capture rich semantic information. For the multi-granularity capability, we propose a multi-choice learning scheme during training, enabling each click to generate masks at multiple levels that correspond to multiple ground-truth masks. Notably, this work represents the first attempt to jointly train a model on SA-1B, generic, and part segmentation datasets. Experimental results and visualizations demonstrate that our model successfully achieves semantic-awareness and granularity-abundance. Furthermore, co", "metrics": null, "error": null, "parent_run_id": "web_classification_variant_0_20231205_120253_104100_1", "start_time": "2023-12-05T04:03:25.608387Z", "end_time": "2023-12-05T04:03:26.033037Z", "index": 1, "api_calls": [{"name": "fetch_text_content_from_url", "type": "Tool", "inputs": {"url": "https://arxiv.org/abs/2307.04767"}, "output": "\n\n\n [2307.04767] Semantic-SAM: Segment and Recognize Anything at Any Granularity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n > cs > arXiv:2307.04767\n  \n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nopen search\n\n\n\n\n\n\nGO\n\n\n\nopen navigation menu\n\n\nquick links\n\nLogin\nHelp Pages\nAbout\n\n\n\n\n\n\n\n\n\n\n\n\nComputer Science > Computer Vision and Pattern Recognition\n\n\narXiv:2307.04767 (cs)\n    \n\n\n\n\n  [Submitted on 10 Jul 2023]\nTitle:Semantic-SAM: Segment and Recognize Anything at Any Granularity\nAuthors:Feng Li, Hao Zhang, Peize Sun, Xueyan Zou, Shilong Liu, Jianwei Yang, Chunyuan Li, Lei Zhang, Jianfeng Gao Download a PDF of the paper titled Semantic-SAM: Segment and Recognize Anything at Any Granularity, by Feng Li and 8 other authors\nDownload PDF\n\nAbstract:In this paper, we introduce Semantic-SAM, a universal image segmentation model to enable segment and recognize anything at any desired granularity. Our model offers two key advantages: semantic-awareness and granularity-abundance. To achieve semantic-awareness, we consolidate multiple datasets across three granularities and introduce decoupled classification for objects and parts. This allows our model to capture rich semantic information. For the multi-granularity capability, we propose a multi-choice learning scheme during training, enabling each click to generate masks at multiple levels that correspond to multiple ground-truth masks. Notably, this work represents the first attempt to jointly train a model on SA-1B, generic, and part segmentation datasets. Experimental results and visualizations demonstrate that our model successfully achieves semantic-awareness and granularity-abundance. Furthermore, co", "start_time": 1701749005.608924, "end_time": 1701749006.032803, "error": null, "children": null, "node_name": "fetch_text_content_from_url"}], "variant_id": "", "cached_run_id": null, "cached_flow_run_id": null, "logs": {"stdout": "", "stderr": ""}, "system_metrics": {"duration": 0.42465}, "result": "\n\n\n [2307.04767] Semantic-SAM: Segment and Recognize Anything at Any Granularity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n > cs > arXiv:2307.04767\n  \n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nopen search\n\n\n\n\n\n\nGO\n\n\n\nopen navigation menu\n\n\nquick links\n\nLogin\nHelp Pages\nAbout\n\n\n\n\n\n\n\n\n\n\n\n\nComputer Science > Computer Vision and Pattern Recognition\n\n\narXiv:2307.04767 (cs)\n    \n\n\n\n\n  [Submitted on 10 Jul 2023]\nTitle:Semantic-SAM: Segment and Recognize Anything at Any Granularity\nAuthors:Feng Li, Hao Zhang, Peize Sun, Xueyan Zou, Shilong Liu, Jianwei Yang, Chunyuan Li, Lei Zhang, Jianfeng Gao Download a PDF of the paper titled Semantic-SAM: Segment and Recognize Anything at Any Granularity, by Feng Li and 8 other authors\nDownload PDF\n\nAbstract:In this paper, we introduce Semantic-SAM, a universal image segmentation model to enable segment and recognize anything at any desired granularity. Our model offers two key advantages: semantic-awareness and granularity-abundance. To achieve semantic-awareness, we consolidate multiple datasets across three granularities and introduce decoupled classification for objects and parts. This allows our model to capture rich semantic information. For the multi-granularity capability, we propose a multi-choice learning scheme during training, enabling each click to generate masks at multiple levels that correspond to multiple ground-truth masks. Notably, this work represents the first attempt to jointly train a model on SA-1B, generic, and part segmentation datasets. Experimental results and visualizations demonstrate that our model successfully achieves semantic-awareness and granularity-abundance. Furthermore, co"}, "start_time": "2023-12-05T04:03:25.608387", "end_time": "2023-12-05T04:03:26.033037", "status": "Completed"}